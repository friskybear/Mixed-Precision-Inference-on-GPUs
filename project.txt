Modern GPUs provide multiple execution paths for numerical computation, including general-purpose CUDA cores and specialized Tensor Cores, each with different performance characteristics. At the same time, reducing numerical precision is a key technique for improving performance and lowering memory footprint during neural network inference.

In this project, you should study mixed-precision inference on GPUs as a performance problem, by implementing and comparing different execution strategies.

Goal
The goal of this project is to analyze the performance impact of mixed-precision inference on GPUs.

You should implement a neural-network inference workload and evaluate how different precision formats and execution units affect:

Runtime and throughput

Memory bandwidth usage

Numerical accuracy relative to an FP32 baseline

Correctness is required, but performance analysis is the primary objective.
Option 2 â€” Mixed Precision with Row-Wise Scaling
Description In this option, you should focus on reducing memory footprint and numerical range issues by combining mixed precision with row-wise scaling of weights.

The idea is to factor out a scale value from each row of a weight matrix so that the remaining values can be stored in lower precision.

Expectations You should:

Implement an FP32 baseline

Implement mixed-precision inference on CUDA cores

Apply row-wise scaling to weight matrices to reduce numerical range

Store scaled weights in lower precision (e.g., FP16)

Store scale factors separately and apply them during inference

You should analyze how scaling affects:

Memory footprint

Performance

Numerical accuracy

Workload Scope
You should use a simple inference workload such as:

A single-layer or two-layer MLP

A dense linear layer followed by a nonlinearity

Training is not required. The workload should be chosen to make performance differences clear and measurable.

Evaluation and Reporting
Your final report should include:

Description of the implementation

Performance comparison against the FP32 baseline

Analysis of precision-related tradeoffs

Discussion of GPU execution behavior

Your work should demonstrate a clear understanding of how mixed precision and GPU hardware features affect inference performance.
